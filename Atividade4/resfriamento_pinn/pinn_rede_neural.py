# -*- coding: utf-8 -*-
"""pinn_rede_neural.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cAYI0d1v97Cbmdf9oOhlDjIPo1eO73Oi

#### Implementação do modelo PINN para extrapolação dos dados utilizados no treinamento.
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torch.utils.data as thdat

# ------------------------------------------------------------------------------
# Define uma função que converte arrays em tensores pytorch.
# ------------------------------------------------------------------------------

def np_to_th(x):
    n_samples = len(x)
    return torch.from_numpy(x).float().reshape(n_samples, -1)

# ------------------------------------------------------------------------------
# Define o modelo.
# ------------------------------------------------------------------------------

class pinn(nn.Module):

  def __init__(
      self,
      input_dim,
      output_dim,
      n_units=100,
      epochs=5000,
      loss=nn.MSELoss(),
      lr=1e-3,
      loss2=None,
      loss2_weight=0.1
      ) -> None:
      super().__init__()

      self.epochs = epochs
      self.lr = lr
      self.n_units= n_units
      self.loss = loss
      self.loss2 = loss2
      self.loss2_weight = loss2_weight

      self.layers = nnSequential(
          nn.Linear(input_dim, self.n_units),
          nn.ReLU(),
          nn.Linear(self.n_units, self.n_units),
          nn.ReLU(),
          nn.Linear(self.n_units, self.n_units),
          nn.ReLU(),
          nn.Linear(self.n_units, self.n_units),
          nn.ReLU()
      )

      self.out = nn.Linear(self.n_units, output_dim)


  def forward(self,x):
    h = self.layers(x)

    out = self.out(h)

    return out

#-------------------------------------------------------------------------------
# Dados de treinamento para tensores, otimizador e perda,
# treinamento e previsão do modelo.
#-------------------------------------------------------------------------------

  def fit(self, x, y):
    x_train = np_to_th(x)
    y_train = np_to_th(y)

    optimiser = optim.Adam(self.parameters(), lr=self.lr)

    self.train()

    losses = []

    for epoch in range(self.epochs):
      optimiser.zero_grad()                      # Zera os gradientes acumulados

      outputs = self.forward(x_train)            # Calcula a predição
      loss = self.loss(y_train, outputs)      # Avalia a 1ª perda (Desvio quadr)
      if self.loss2:
        loss += self.loss2_weight * self.loss2(self) # Avalia a '2ª' perda com base na eq diferencial

      loss.backward()                # Calcula os gradientes via backpropagation
      optimiser.step()               # Atualiza os pesos e bias da rede
      losses.append(loss.item())
      if epoch % int(self.epochs / 10) == 0:
        print(f"Epoch {ep}/{self.epochs}, loss: {losses[-1]:.2f}")
      return losses

#-------------------------------------------------------------------------------
# Exemplificando o uso de loss2
#-------------------------------------------------------------------------------

#Se loss2_weight = 0.0: a PINN não influencia nada

#Se loss2_weight = 1.0: a física (eq diff) e os dados têm peso igual

#Se loss2_weight = 10.0: a física domina o aprendizado
#-------------------------------------------------------------------------------


# Definimos a predição do modelo:

  def predict(self, X):
    self.eval()
    out = self.forward(np_to_th(X))
    return out.detach().numpy()
#-------------------------------------------------------------------------------
# Define um modelo para prever, a partir dos dados treinados e da equação
# diferencial, a taxa de resfriamento r.
#-------------------------------------------------------------------------------

class Taxa(pinn):
    def __init__(
        self,
        input_dim,
        output_dim,
        n_units=100,
        epochs=1000,
        loss=nn.MSELoss(),
        lr=0.001,
        loss2=None,
        loss2_weight=0.1,
    ) -> None:
        super().__init__(
            input_dim, output_dim, n_units, epochs, loss, lr, loss2, loss2_weight
        )

        self.r = nn.Parameter(data=torch.tensor([0.]))

